<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>TOMG-Bench</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <style>
    .scrollable-table {
      max-height: 500px;
      overflow-y: auto;
    }
  </style>
  <style>
    .footer p {
      font-size: 0.6em;
      color: #999999;
    }
  </style>
  .simple-icons--huggingface {
    display: inline-block;
    width: 24px;
    height: 24px;
    --svg: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 24 24'%3E%3Cpath fill='%23000' d='M1.445 11.506c0 1.102.167 2.158.484 3.156c-.038-.003-.069-.006-.106-.006c-.42 0-.801.16-1.07.452c-.345.373-.498.833-.431 1.293a1.6 1.6 0 0 0 .214.597a1.43 1.43 0 0 0-.484.758c-.065.245-.131.754.215 1.28l-.063.105c-.208.392-.22.837-.037 1.25c.279.626.97 1.118 2.313 1.647c.835.329 1.599.54 1.605.543c1.105.284 2.104.427 2.97.427c1.417 0 2.475-.384 3.152-1.144c1.538.265 2.79.14 3.592.006c.677.755 1.733 1.139 3.147 1.139c.864 0 1.864-.143 2.969-.428c.006-.002.77-.214 1.605-.543c1.343-.53 2.034-1.021 2.313-1.647a1.4 1.4 0 0 0-.037-1.25l-.063-.105c.346-.525.28-1.035.215-1.28a1.43 1.43 0 0 0-.484-.758q.166-.27.215-.597c.066-.46-.087-.92-.432-1.293a1.43 1.43 0 0 0-1.07-.452l-.06.002a10.4 10.4 0 0 0 .485-3.152c0-5.807-4.736-10.514-10.579-10.514c-5.842 0-10.578 4.707-10.578 10.514m10.578-9.483c5.273 0 9.548 4.246 9.548 9.483a9.4 9.4 0 0 1-.27 2.236l-.011-.015a1.42 1.42 0 0 0-1.108-.506c-.352 0-.714.115-1.076.344c-.24.151-.506.422-.78.76c-.253-.35-.607-.584-1.013-.647a1.5 1.5 0 0 0-.235-.018c-.926 0-1.482.8-1.693 1.518c-.105.243-.607 1.348-1.361 2.098c-1.169 1.16-1.446 2.353-.84 3.638a9.3 9.3 0 0 1-2.365-.006c.59-1.212.363-2.439-.843-3.632c-.755-.75-1.256-1.855-1.361-2.098c-.21-.718-.767-1.518-1.694-1.518q-.117 0-.234.018c-.406.063-.76.297-1.014.646c-.273-.337-.539-.608-.779-.76c-.362-.228-.724-.343-1.076-.343c-.427 0-.81.17-1.082.478a9.4 9.4 0 0 1-.26-2.193c0-5.237 4.275-9.483 9.547-9.483m-3.379 4.98a1.36 1.36 0 0 0-.629 2.563c.351.186.489-.526.836-.648c.311-.11.841.399 1.008.086a1.36 1.36 0 0 0-.562-1.84a1.4 1.4 0 0 0-.653-.16m6.84 0a1.36 1.36 0 0 0-1.215 2c.168.314.698-.195 1.009-.085c.347.122.486.835.838.648a1.36 1.36 0 0 0 .562-1.84a1.37 1.37 0 0 0-1.193-.722M5.729 8.423a.877.877 0 0 0-.877.877c0 .484.393.877.877.877a.877.877 0 0 0 .877-.877a.877.877 0 0 0-.877-.877m12.644 0a.88.88 0 0 0-.88.877a.88.88 0 0 0 .88.877a.877.877 0 0 0 .876-.877a.877.877 0 0 0-.877-.877m-9.58 3.037c-.178-.003-.279.11-.279.416c0 .81.388 2.125 1.428 2.924c.207-.712 1.346-1.283 1.508-1.201c.232.116.22.441.608.726c.388-.285.374-.61.605-.726c.163-.082 1.301.489 1.508 1.201c1.04-.799 1.428-2.114 1.428-2.924c0-1.221-1.583.64-3.541.649c-1.469-.007-2.727-1.056-3.264-1.065m-4.48 3.018c.58.365 1.696 2.275 2.106 3.018a.66.66 0 0 0 .582.353c.418 0 .746-.414.039-.94c-1.064-.79-.692-2.084-.184-2.164a.4.4 0 0 1 .066-.004c.462 0 .666.79.666.79s.596 1.49 1.622 2.508c.942.935 1.062 1.703.496 2.666c-.016-.004-.016.023-.148.215a1.9 1.9 0 0 1-.72.615c-.505.227-1.139.27-1.783.27a11.8 11.8 0 0 1-2.697-.337c-.03-.007-3.65-.956-3.192-1.822c.077-.145.204-.203.364-.203c.646 0 1.823.955 2.328.955c.113 0 .196-.086.228-.203c.225-.805-3.278-1.052-2.984-2.164c.052-.197.193-.276.39-.276c.854 0 2.77 1.493 3.173 1.493q.046 0 .064-.028c.201-.322.11-.586-1.309-1.44c-1.418-.853-2.431-1.328-1.865-1.94c.065-.072.157-.102.27-.102c.86 0 2.894 1.84 2.894 1.84s.549.568.881.568a.2.2 0 0 0 .186-.105c.235-.395-2.186-2.219-2.323-2.971c-.092-.51.064-.768.356-.768c0 .008.17-.029.494.176m16.226.592c-.137.752-2.558 2.576-2.323 2.97c.044.074.11.106.186.106c.332 0 .88-.568.88-.568s2.034-1.84 2.896-1.84c.112 0 .204.03.269.101c.566.613-.447 1.088-1.865 1.942c-1.419.853-1.51 1.116-1.309 1.44q.018.027.064.027c.402 0 2.318-1.493 3.172-1.493c.198 0 .34.079.391.276c.294 1.112-3.21 1.36-2.984 2.164c.032.117.115.203.228.203c.505 0 1.682-.955 2.328-.955c.16 0 .287.058.364.203c.459.866-3.163 1.815-3.192 1.822c-.596.154-1.66.336-2.697.336c-.636 0-1.261-.04-1.764-.26a1.9 1.9 0 0 1-.739-.624c-.04-.069-.102-.148-.142-.205c-.573-.968-.455-1.738.49-2.676c1.026-1.019 1.621-2.508 1.621-2.508s.205-.79.666-.79a.4.4 0 0 1 .067.004c.508.08.88 1.374-.184 2.165c-.707.525-.38.94.04.94a.66.66 0 0 0 .581-.354c.41-.743 1.527-2.653 2.106-3.018c.559-.353.99-.182.85.592'/%3E%3C/svg%3E");
    background-color: currentColor;
    -webkit-mask-image: var(--svg);
    mask-image: var(--svg);
    -webkit-mask-repeat: no-repeat;
    mask-repeat: no-repeat;
    -webkit-mask-size: 100% 100%;
    mask-size: 100% 100%;
  }
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">TOMG-Bench: Evaluating LLMs on Text-based Open Molecule Generation</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://phenixace.github.io" target="_blank">Jiatong Li</a><sup>*</sup><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=U-b_eXkAAAAJ" target="_blank">Junxian Li</a><sup>*</sup><sup>2</sup>,</span>
                  <span class="author-block">
                    <a href="https://liuyunqing.github.io" target="_blank">Yunqing Liu</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=Ox6SxpoAAAAJ" target="_blank">Dongzhan Zhou</a><sup>3</sup>,</span>
                  <span class="author-block">
                    <a href="https://www.polyu.edu.hk/en/comp/people/academic-staff/prof-li-qing/" target="_blank">Qing Li</a><sup>1</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>Hong Kong Polytechnic University, <sup>2</sup>Shanghai Jiao Tong University, <sup>3</sup>Shanghai AI Lab<br>UnderReview</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2412.14642" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/phenixace/TOMG-Bench" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2412.14642" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
                <!-- Huggingface Dataset Link-->
                <span class="link-block">
                  <a href="https://huggingface.co/datasets/Duke-de-Artois/TOMG-Bench" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    &#x1F917;
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          In this paper, we propose Text-based Open Molecule Generation Benchmark (TOMG-Bench), the first benchmark to evaluate the open-domain molecule generation capability of LLMs. TOMG-Bench encompasses a dataset of three major tasks: molecule editing (MolEdit), molecule optimization (MolOpt), and customized molecule generation (MolCustom). Each task further contains three subtasks, with each subtask comprising 5,000 test samples. Given the inherent complexity of open molecule generation, we have also developed an automated evaluation system that helps measure both the quality and the accuracy of the generated molecules. Our comprehensive benchmarking of 25 LLMs reveals the current limitations and potential areas for improvement in text-guided molecule discovery. Furthermore, with the assistance of OpenMolIns, a specialized instruction tuning dataset proposed for solving challenges raised by TOMG-Bench, Llama3.1-8B could outperform all the open-source general LLMs, even surpassing GPT-3.5-turbo by 46.5% on TOMG-Bench.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!--Leaderboard -->
<section class="hero is-small light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Leaderboard</h2>
      <div class="content">
        <div class="scrollable-table">
        <table class="table is-fullwidth is-hoverable">
          <thead>
            <tr>
              <th>Rank</th>
              <th>Model</th>
              <th>#Parameters</th>
              <th>A̅cc (%)</th>
              <th>wA̅cc (%)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>1</td>
              <td>Claude-3.5</td>
              <td>N/A</td>
              <td>51.10</td>
              <td>35.92</td>
            </tr>
            <tr>
              <td>2</td>
              <td>Gemini-1.5-pro</td>
              <td>N/A</td>
              <td>52.25</td>
              <td>34.80</td>
            </tr>
            <tr>
              <td>3</td>
              <td>GPT-4-turbo</td>
              <td>N/A</td>
              <td>50.74</td>
              <td>34.23</td>
            </tr>
            <tr>
              <td>4</td>
              <td>GPT-4o</td>
              <td>N/A</td>
              <td>49.08</td>
              <td>32.29</td>
            </tr>
            <tr>
              <td>5</td>
              <td>Claude-3</td>
              <td>N/A</td>
              <td>46.14</td>
              <td>30.47</td>
            </tr>
            <tr>
              <td>6</td>
              <td>OpenMolIns-large (Llama-3.1-8B)</td>
              <td>8B</td>
              <td>43.1</td>
              <td>27.22</td>
            </tr>
            <tr>
              <td>7</td>
              <td>OpenMolIns-xlarge (Galactica-125M)</td>
              <td>125M</td>
              <td>44.48</td>
              <td>25.73</td>
            </tr>
            <tr>
              <td>8</td>
              <td>Llama3-70B-Instruct (Int4)</td>
              <td>70B</td>
              <td>38.54</td>
              <td>23.93</td>
            </tr>
            <tr>
              <td>9</td>
              <td>OpenMolIns-large (Galactica-125M)</td>
              <td>125M</td>
              <td>39.28</td>
              <td>23.42</td>
            </tr>
            <tr>
              <td>10</td>
              <td>OpenMolIns-medium (Galactica-125M)</td>
              <td>125M</td>
              <td>34.54</td>
              <td>19.89</td>
            </tr>
            <tr>
              <td>11</td>
              <td>GPT-3.5-turbo</td>
              <td>N/A</td>
              <td>28.93</td>
              <td>18.58</td>
            </tr>
            <tr>
              <td>12</td>
              <td>OpenMolIns-small (Galactica-125M)</td>
              <td>125M</td>
              <td>24.17</td>
              <td>15.18</td>
            </tr>
            <tr>
              <td>13</td>
              <td>Llama3.1-8B-Instruct</td>
              <td>8B</td>
              <td>26.26</td>
              <td>14.09</td>
            </tr>
            <tr>
              <td>14</td>
              <td>Llama3-8B-Instruct</td>
              <td>8B</td>
              <td>26.40</td>
              <td>13.75</td>
            </tr>
            <tr>
              <td>15</td>
              <td>chatglm-9B</td>
              <td>9B</td>
              <td>18.50</td>
              <td>13.13(7)</td>
            </tr>
            <tr>
              <td>16</td>
              <td>OpenMolIns-light (Galactica-125M)</td>
              <td>125M</td>
              <td>20.95</td>
              <td>13.13(6)</td>
            </tr>
            <tr>
              <td>17</td>
              <td>OpenMolIns-large (Llama3.2-1B)</td>
              <td>1B</td>
              <td>14.11</td>
              <td>8.10</td>
            </tr>
            <tr>
              <td>18</td>
              <td>yi-1.5-9B</td>
              <td>9B</td>
              <td>14.10</td>
              <td>7.32</td>
            </tr>
            <tr>
              <td>19</td>
              <td>Mistral-7B-Instruct-v0.2</td>
              <td>7B</td>
              <td>11.17</td>
              <td>4.81</td>
            </tr>
            <tr>
              <td>20</td>
              <td>BioT5-base</td>
              <td>250M</td>
              <td>24.19</td>
              <td>4.21</td>
            </tr>
            <tr>
              <td>21</td>
              <td>MolT5-large</td>
              <td>780M</td>
              <td>23.11</td>
              <td>2.89</td>
            </tr>
            <tr>
              <td>22</td>
              <td>Llama-3.1-1B-Instruct</td>
              <td>1B</td>
              <td>3.95</td>
              <td>1.99</td>
            </tr>
            <tr>
              <td>23</td>
              <td>MolT5-base</td>
              <td>250M</td>
              <td>11.11</td>
              <td>1.30(0)</td>
            </tr>
            <tr>
              <td>24</td>
              <td>MolT5-small</td>
              <td>80M</td>
              <td>11.55</td>
              <td>1.29(9)</td>
            </tr>
            <tr>
              <td>25</td>
              <td>Qwen2-7B-Instruct</td>
              <td>7B</td>
              <td>0.18</td>
              <td>0.15</td>
            </tr>
          </tbody>
        </table> 
      </div>
      </div>
    </div>
  </section>
<!--End Leaderboard -->


<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{li2024tomgbenchevaluatingllmstextbased,
        title={TOMG-Bench: Evaluating LLMs on Text-based Open Molecule Generation}, 
        author={Jiatong Li and Junxian Li and Yunqing Liu and Dongzhan Zhou and Qing Li},
        year={2024},
        eprint={2412.14642},
        archivePrefix={arXiv},
        primaryClass={cs.CL},
        url={https://arxiv.org/abs/2412.14642}, 
  }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="container is-max-desktop content">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
